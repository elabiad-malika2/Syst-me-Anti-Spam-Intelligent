{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99831fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset : (28811, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_text\n",
       "0  any software just for 15 $ - 99 $ understandin...      1       spam\n",
       "1  perspective on ferc regulatory action client c...      0        ham\n",
       "2  wanted to try ci 4 lis but thought it was way ...      1       spam\n",
       "3  enron / hpl actuals for december 11 , 2000 tec...      0        ham\n",
       "4  looking for cheap high - quality software ? ro...      1       spam"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '../Data/cleaned/cleaned_data.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, encoding='latin-1')\n",
    "\n",
    "print(f\"Taille du dataset : {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f483c08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elabi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Téléchargement de la liste des stopwords (mots vides)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = PorterStemmer() \n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9b1b8",
   "metadata": {},
   "source": [
    "#  NLP Text Cleaning Pipeline — Prétraitement du Dataset\n",
    "\n",
    "Ce notebook effectue le prétraitement complet d’un dataset textuel composé de **28 811 lignes**.  \n",
    "L’objectif est de nettoyer les textes avant l’entraînement d’un modèle de classification NLP.\n",
    "\n",
    "##  Étapes réalisées dans ce notebook :\n",
    "\n",
    "### 1. Chargement et inspection des données\n",
    "- Lecture du dataset\n",
    "- Vérification des valeurs manquantes\n",
    "- Suppression des lignes contenant `NaN`\n",
    "\n",
    "### 2. Prétraitement du texte\n",
    "Les opérations suivantes sont appliquées à chaque texte :\n",
    "\n",
    "- Conversion en **minuscules**\n",
    "- Suppression de la **ponctuation** et des caractères spéciaux via `regex`\n",
    "- **Tokenisation**\n",
    "- Suppression des **stopwords (NLTK stopwords en anglais)**\n",
    "- Application du **Stemming (PorterStemmer)** pour réduire les mots à leur racine\n",
    "\n",
    "### 3. Fonction `clean_word()`\n",
    "Cette fonction transforme chaque texte en une version nettoyée, optimisée pour :\n",
    "- TF-IDF\n",
    "- bag-of-words\n",
    "- vectorisation dans une base vectorielle\n",
    "- classification machine learning\n",
    "\n",
    "### 4. Sauvegarde du dataset nettoyé\n",
    "Le dataset final nettoyé est sauvegardé pour être utilisé dans les étapes suivantes du pipeline NLP.\n",
    "\n",
    "---\n",
    " **Remarque :**  \n",
    "Le stemming est utilisé car il est plus rapide et adapté à un dataset de taille moyenne (28k lignes) sans perte significative de performance pour la classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832e7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stopwords + stemming\n",
    "    clean_words = [\n",
    "        stemmer.stem(word) \n",
    "        for word in words \n",
    "        if word not in stop_words\n",
    "    ]\n",
    "\n",
    "    return \" \".join(clean_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093d850",
   "metadata": {},
   "source": [
    "###  Application de la fonction de nettoyage sur la colonne *text*\n",
    "\n",
    "Dans cette étape, nous appliquons la fonction `clean_word` (fonction de prétraitement du texte) à l’ensemble de la colonne **text** du dataset.  \n",
    "L’objectif est de transformer chaque texte brut en une version nettoyée prête pour l’analyse ou l’entraînement d’un modèle NLP.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c3cd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>softwar understand oem softwar lead temptat fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>perspect ferc regulatori action client conf ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>want tri ci li thought way expens viagra per d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>enron hpl actual decemb teco tap enron hpl ga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>look cheap high qualiti softwar rotat napoleon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  any software just for 15 $ - 99 $ understandin...   \n",
       "1  perspective on ferc regulatory action client c...   \n",
       "2  wanted to try ci 4 lis but thought it was way ...   \n",
       "3  enron / hpl actuals for december 11 , 2000 tec...   \n",
       "4  looking for cheap high - quality software ? ro...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  softwar understand oem softwar lead temptat fi...  \n",
       "1  perspect ferc regulatori action client conf ca...  \n",
       "2  want tri ci li thought way expens viagra per d...  \n",
       "3  enron hpl actual decemb teco tap enron hpl ga ...  \n",
       "4  look cheap high qualiti softwar rotat napoleon...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df['clean_text'] = df['text'].apply(clean_word)\n",
    "\n",
    "display(df[['text', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91634324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_final = df[['label', 'label_text', 'clean_text']]\n",
    "\n",
    "\n",
    "df_final.to_csv('../Data/processed/processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72401c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
